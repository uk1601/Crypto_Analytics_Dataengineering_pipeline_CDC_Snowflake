{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "Crypto Data Loading with Snowpark\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Data Engineering with Snowpark for Cryptocurrency Data\n",
    "# Script:       crypto_data_loader.py\n",
    "# Last Updated: February 27, 2025\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# Define our crypto tables and corresponding file names\n",
    "CRYPTO_TABLES = {\n",
    "    'BTC': 'BTC_raw_daily.csv',\n",
    "    'DOGE': 'DOGE_raw_daily.csv',\n",
    "    'ETH': 'ETH_raw_daily.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# SNOWFLAKE ADVANTAGE: Schema detection\n",
    "# SNOWFLAKE ADVANTAGE: Data ingestion with COPY\n",
    "\n",
    "def load_raw_table(session, table_name, file_name, schema=\"RAW_CRYPTO\"):\n",
    "    \"\"\"\n",
    "    Load data from S3 stage into Snowflake tables\n",
    "    \n",
    "    Parameters:\n",
    "    session: Snowpark session\n",
    "    table_name: Table name (BTC, DOGE, ETH)\n",
    "    file_name: File name in the stage (e.g., BTC_raw_daily.csv)\n",
    "    schema: Schema name\n",
    "    \"\"\"\n",
    "    print(f\"Loading {table_name} from {file_name}\")\n",
    "    session.use_schema(schema)\n",
    "    \n",
    "    # Define the FULLY QUALIFIED stage path to the file\n",
    "    stage_path = f\"@CRYPTO_DB.INTEGRATIONS.CRYPTO_RAW_STAGE/{file_name}\"\n",
    "    \n",
    "    # Read the CSV file from the stage\n",
    "    df = session.read.option(\"header\", True) \\\n",
    "                     .option(\"infer_schema\", True) \\\n",
    "                     .csv(stage_path)\n",
    "    \n",
    "    # Print column names to debug\n",
    "    print(f\"Columns in dataframe: {df.columns}\")\n",
    "    \n",
    "    # Create a case-insensitive mapping for columns\n",
    "    columns_map = {col.lower(): col for col in df.columns}\n",
    "    \n",
    "    # Convert date string to DATE type - handling different case possibilities\n",
    "    if \"date\" in columns_map:\n",
    "        date_col = columns_map[\"date\"]\n",
    "        df = df.with_column(date_col, F.to_date(df[date_col]))\n",
    "\n",
    "    \n",
    "    # Convert numeric columns to FLOAT - handling different case possibilities\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\", \"volume\", \"adjclose\"]:\n",
    "        if col.lower() in columns_map:\n",
    "            actual_col = columns_map[col.lower()]\n",
    "            df = df.with_column(actual_col, F.to_double(df[actual_col]))\n",
    "      \n",
    "    \n",
    "    # Copy data into table\n",
    "    df.write.mode(\"overwrite\").save_as_table(f\"{schema}.{table_name}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {table_name}\")\n",
    "    \n",
    "    # Return row count\n",
    "    return session.table(f\"{schema}.{table_name}\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "# SNOWFLAKE ADVANTAGE: Warehouse elasticity (dynamic scaling)\n",
    "def load_all_crypto_tables(session, warehouse_name=\"CRYPTO_WH\"):\n",
    "    \"\"\"\n",
    "    Load all cryptocurrency tables with warehouse scaling\n",
    "    \n",
    "    Parameters:\n",
    "    session: Snowpark session\n",
    "    warehouse_name: The name of the Snowflake warehouse to use\n",
    "    \"\"\"\n",
    "    # Set role to CRYPTO_ROLE\n",
    "    session.sql(\"USE ROLE CRYPTO_ROLE\").collect()\n",
    "    \n",
    "    # Scale up warehouse for faster loading\n",
    "    session.sql(f\"ALTER WAREHOUSE {warehouse_name} SET WAREHOUSE_SIZE = LARGE WAIT_FOR_COMPLETION = TRUE\").collect()\n",
    "    \n",
    "    try:\n",
    "        # Explicitly use CRYPTO_ROLE for schema creation\n",
    "        session.sql(\"USE ROLE CRYPTO_ROLE\").collect()\n",
    "        # Create schema if it doesn't exist\n",
    "        session.sql(\"CREATE SCHEMA IF NOT EXISTS RAW_CRYPTO\").collect()\n",
    "        \n",
    "        # Create tables if they don't exist\n",
    "        for table_name in CRYPTO_TABLES.keys():\n",
    "            # Use CRYPTO_ROLE explicitly for each table creation\n",
    "            session.sql(\"USE ROLE CRYPTO_ROLE\").collect()\n",
    "            session.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS RAW_CRYPTO.{table_name} (\n",
    "                date DATE PRIMARY KEY,\n",
    "                open FLOAT,\n",
    "                high FLOAT,\n",
    "                low FLOAT,\n",
    "                close FLOAT,\n",
    "                volume FLOAT,\n",
    "                adjclose FLOAT\n",
    "            )\n",
    "            \"\"\").collect()\n",
    "        \n",
    "        # Load data for each table\n",
    "        results = {}\n",
    "        for table_name, file_name in CRYPTO_TABLES.items():\n",
    "            # Use CRYPTO_ROLE for data loading as well\n",
    "            session.sql(\"USE ROLE CRYPTO_ROLE\").collect()\n",
    "            row_count = load_raw_table(session, table_name, file_name)\n",
    "            results[table_name] = row_count\n",
    "        \n",
    "        return results\n",
    "            \n",
    "    finally:\n",
    "        # Scale down warehouse when done\n",
    "        session.sql(f\"ALTER WAREHOUSE {warehouse_name} SET WAREHOUSE_SIZE = XSMALL\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "def validate_crypto_tables(session, schema=\"RAW_CRYPTO\"):\n",
    "    \"\"\"\n",
    "    Validate the loaded crypto tables\n",
    "    \"\"\"\n",
    "    print(\"Validating loaded tables:\")\n",
    "    \n",
    "    # First, get actual column names to check their case\n",
    "    for table_name in [\"BTC\", \"DOGE\", \"ETH\"]:\n",
    "        # Get column names from the table\n",
    "        columns = session.table(f\"{schema}.{table_name}\").columns\n",
    "        print(f\"Actual columns in {table_name}: {columns}\")\n",
    "        \n",
    "        # Find the date column (case insensitive)\n",
    "        date_column = next((col for col in columns if col.upper() == \"DATE\"), None)\n",
    "        \n",
    "        if date_column:\n",
    "            # Use the actual column name in the query\n",
    "            date_range = session.sql(f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(\"{date_column}\") as min_date, \n",
    "                    MAX(\"{date_column}\") as max_date \n",
    "                FROM {schema}.{table_name}\n",
    "            \"\"\").collect()[0]\n",
    "            \n",
    "            print(f\"{table_name} data range: {date_range['MIN_DATE']} to {date_range['MAX_DATE']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Main execution function\n",
    "def main(session):\n",
    "    \"\"\"\n",
    "    Main function to execute the data loading process\n",
    "    \n",
    "    Parameters:\n",
    "    session: Snowpark session\n",
    "    \"\"\"\n",
    "    print(\"Starting cryptocurrency data loading process...\")\n",
    "    \n",
    "    # Use correct role\n",
    "    session.sql(\"USE ROLE ACCOUNTADMIN\").collect()\n",
    "    \n",
    "    # Load all tables\n",
    "    results = load_all_crypto_tables(session)\n",
    "    print(f\"Data loading complete! Rows loaded: {results}\")\n",
    "    \n",
    "    # Validate loaded tables\n",
    "    validate_crypto_tables(session)\n",
    "    \n",
    "    print(\"Process completed successfully!\")\n",
    "\n",
    "\n",
    "# For executing from a Snowflake notebook\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a Snowpark session\n",
    "    from snowflake.snowpark import Session\n",
    "    import snowflake.snowpark.functions as F\n",
    "    with Session.builder.getOrCreate() as session:\n",
    "        main(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  },
  "lastEditStatus": {
   "authorEmail": "prasanna.vi@northeastern.edu",
   "authorId": "726488193010",
   "authorName": "udaykiran",
   "lastEditTime": 1740844645116,
   "notebookId": "cedfd3uzhqkvnkfltunp",
   "sessionId": "f3456571-7746-4848-b39d-d7c9f18874e4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
